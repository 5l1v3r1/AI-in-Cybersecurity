{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Identifying Phishing Websites**\n",
    "\n",
    "The goal of this document is to review how best to evaluate websites for being part of a phishing scam.  This can be done using the Phishing Website Data Set from the UCI Machine Learning Repository.  This data set has 31 features for evaluation, which are detailed in _Phishing Website Features_, a paper written by Rami M. Mohammad, Fadi Thabtah, and Lee McCluskey.  These three researchers developed a classification scheme which can be broken down into the following thirty-one categories:\n",
    "\n",
    "- Having IP Address\n",
    "- URL Length\n",
    "- Shortining Service\n",
    "- Having @ Symbol\n",
    "- Double Slash Redirecting\n",
    "- Prefix Suffix\n",
    "- Having Sub-Domain\n",
    "- SSL Final State\n",
    "- Domain Registration Length\n",
    "- Favicon\n",
    "- port\n",
    "- HTTPS Token\n",
    "- Request URL\n",
    "- URL of Anchor\n",
    "- Link in Tags\n",
    "- SFH\n",
    "- Submitting to Email\n",
    "- Abnormal URL\n",
    "- Redirect\n",
    "- On MouseOver\n",
    "- Right Click\n",
    "- Pop-up Window\n",
    "- Iframe\n",
    "- Age of Domain\n",
    "- DNS Record\n",
    "- Web Traffic\n",
    "- Page Rank\n",
    "- Google Index\n",
    "- Links Pointing to Page\n",
    "- Statistical Report\n",
    "- Result\n",
    "\n",
    "While these items are being assessed in the data set, they are not labeled as can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   -1  1  1.1  1.2  -1.1  -1.2  -1.3  -1.4  -1.5  1.3  ...  1.9  1.10  -1.11  \\\n",
      "0   1  1    1    1     1    -1     0     1    -1    1  ...    1     1     -1   \n",
      "1   1  0    1    1     1    -1    -1    -1    -1    1  ...    1     1      1   \n",
      "2   1  0    1    1     1    -1    -1    -1     1    1  ...    1     1     -1   \n",
      "3   1  0   -1    1     1    -1     1     1    -1    1  ...   -1     1     -1   \n",
      "4  -1  0   -1    1    -1    -1     1     1    -1    1  ...    1     1      1   \n",
      "\n",
      "   -1.12  -1.13  -1.14  1.11  1.12  -1.15  -1.16  \n",
      "0     -1      0     -1     1     1      1     -1  \n",
      "1     -1      1     -1     1     0     -1     -1  \n",
      "2     -1      1     -1     1    -1      1     -1  \n",
      "3     -1      0     -1     1     1      1      1  \n",
      "4      1      1     -1     1    -1     -1      1  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Execute plot() inline without calling show()\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(os.path.join('Data', 'phishing_dataset.csv'))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the data shows, there is no labeling in the imported data.  Coding methods are not universal across all features either, with some features being binary (-1 or 1) while others are terciary (-1, 0, or 1).  The following table shows how each feature is evaluated in the dataset:\n",
    "\n",
    ">Feature | Rating\n",
    ">--- | ---\n",
    "> Having IP Address | -1, 1\n",
    "> URL Length | -1, 0, 1\n",
    "> Shortining Service | -1, 1\n",
    "> Having @ Symbol | -1, 1\n",
    "> Double Slash Redirecting | -1, 1\n",
    "> Prefix Suffix | -1, 1\n",
    "> Having Sub-Domain | -1, 0, 1\n",
    "> SSL Final State | -1, 0, 1\n",
    "> Domain Registration Length | -1, 1\n",
    "> Favicon | -1, 1\n",
    "> port | -1, 1\n",
    "> HTTPS Token | -1, 1\n",
    "> Request URL | -1, 1\n",
    "> URL of Anchor | -1, 0, 1\n",
    "> Link in Tags | -1, 0, 1\n",
    "> SFH | -1, 0, 1\n",
    "> Submitting to Email | -1, 1\n",
    "> Abnormal URL | -1, 1\n",
    "> Redirect | 0, 1\n",
    "> On MouseOver | -1, 1\n",
    "> Right Click | -1, 1\n",
    "> Pop-up Window | -1, 1\n",
    "> Iframe | -1, 1\n",
    "> Age of Domain | -1, 1\n",
    "> DNS Record | -1, 1\n",
    "> Web Traffic | -1, 0, 1\n",
    "> Page Rank | -1, 1\n",
    "> Google Index | -1, 1\n",
    "> Links Pointing to Page | -1, 0, 1\n",
    "> Statistical Report | -1, 1\n",
    "> Result | -1, 1\n",
    "\n",
    "Knowing this we can evaluate the data initially using the following code.  The focus here is to do a perceptron evaluation, though there are other algorithms which can be used in an attempt to be more accurate.\n",
    "\n",
    "There are 30 features to evaluate (not counting the final column 'Result' because it is a label not a feature).  In order to evaluate this each item needs to have an $x_{1 ... n}$ value and a $w_{1 ... n}$ value.  Meaning that the equation:\n",
    "\n",
    ">$ y = f(x_{1}, x_{2}) = f(w_{1}x_{1} + w_{2}x_{2} + ... + w_{n}x_{n})$\n",
    "\n",
    "If $y = [-1, 1]$ then we assume -1 means the URL is not phishing and assume 1 means the URL is associated with phishing.\n",
    "\n",
    "In order to find the best weights requires we go through the features and identify the best ones to review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  0 \n",
      "\n",
      "Misclassified samples: 1762\n",
      "Accuracy: 0.47 for index:  1 \n",
      "\n",
      "Misclassified samples: 1777\n",
      "Accuracy: 0.46 for index:  2 \n",
      "\n",
      "Misclassified samples: 1910\n",
      "Accuracy: 0.42 for index:  3 \n",
      "\n",
      "Misclassified samples: 1795\n",
      "Accuracy: 0.46 for index:  4 \n",
      "\n",
      "Misclassified samples: 1454\n",
      "Accuracy: 0.56 for index:  5 \n",
      "\n",
      "Misclassified samples: 1338\n",
      "Accuracy: 0.60 for index:  6 \n",
      "\n",
      "Misclassified samples: 388\n",
      "Accuracy: 0.88 for index:  7 \n",
      "\n",
      "Misclassified samples: 2087\n",
      "Accuracy: 0.37 for index:  8 \n",
      "\n",
      "Misclassified samples: 1823\n",
      "Accuracy: 0.45 for index:  9 \n",
      "\n",
      "Misclassified samples: 1880\n",
      "Accuracy: 0.43 for index:  10 \n",
      "\n",
      "Misclassified samples: 1773\n",
      "Accuracy: 0.47 for index:  11 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  12 \n",
      "\n",
      "Misclassified samples: 497\n",
      "Accuracy: 0.85 for index:  13 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  14 \n",
      "\n",
      "Misclassified samples: 1412\n",
      "Accuracy: 0.57 for index:  15 \n",
      "\n",
      "Misclassified samples: 1859\n",
      "Accuracy: 0.44 for index:  16 \n",
      "\n",
      "Misclassified samples: 1764\n",
      "Accuracy: 0.47 for index:  17 \n",
      "\n",
      "Misclassified samples: 1861\n",
      "Accuracy: 0.44 for index:  18 \n",
      "\n",
      "Misclassified samples: 1893\n",
      "Accuracy: 0.43 for index:  19 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  20 \n",
      "\n",
      "Misclassified samples: 1827\n",
      "Accuracy: 0.45 for index:  21 \n",
      "\n",
      "Misclassified samples: 1862\n",
      "Accuracy: 0.44 for index:  22 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  23 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  24 \n",
      "\n",
      "Misclassified samples: 1020\n",
      "Accuracy: 0.69 for index:  25 \n",
      "\n",
      "Misclassified samples: 1629\n",
      "Accuracy: 0.51 for index:  26 \n",
      "\n",
      "Misclassified samples: 1905\n",
      "Accuracy: 0.43 for index:  27 \n",
      "\n",
      "Misclassified samples: 1604\n",
      "Accuracy: 0.52 for index:  28 \n",
      "\n",
      "Misclassified samples: 1925\n",
      "Accuracy: 0.42 for index:  29 \n",
      "\n",
      "Feature Indexes with higher than 60% accuracy are:  [7, 13, 25]\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "high_acc = []\n",
    "\n",
    "for i in range(30):\n",
    "    X = df.iloc[:, [i]].values  #To create weights\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)\n",
    "    \n",
    "    #Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "    p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "    p.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = p.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if acc >= 0.60:\n",
    "        high_acc.append(i)\n",
    "    \n",
    "    print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "    print('Accuracy: %.2f' % acc, 'for feature index: ', i, '\\n')\n",
    "    i =+ 1 \n",
    "    \n",
    "print('Feature Indexes with higher than 60% accuracy are: ', high_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the above iterations, the feature at indexes with the greatest levels of accuracy, accuracy above 0.60, are indexes: 7, 13, and 25.  Let's seporate these out from the others and then review how to get better accuracy with more than one feature being evaluated at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 231\n",
      "Accuracy: 0.90 for indexes: 7 & 13\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 13]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 353\n",
      "Accuracy: 0.84 for indexes: 7 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 417\n",
      "Accuracy: 0.81 for indexes: 13 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [13, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 13 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 300\n",
      "Accuracy: 0.86 for indexes: 7, 13 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 13, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7, 13 & 25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above, we can see most accuracy is in the high 80.0%\n",
    "\n",
    "At this point we've been training on 70% of the data and testing against 30% of the data.  What happens if we do this with 80% of the data used for training and 20% used for testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 929\n",
      "Accuracy: 0.58 for feature index:  0 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  1 \n",
      "\n",
      "Misclassified samples: 1182\n",
      "Accuracy: 0.47 for feature index:  2 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  3 \n",
      "\n",
      "Misclassified samples: 1199\n",
      "Accuracy: 0.46 for feature index:  4 \n",
      "\n",
      "Misclassified samples: 964\n",
      "Accuracy: 0.56 for feature index:  5 \n",
      "\n",
      "Misclassified samples: 942\n",
      "Accuracy: 0.57 for feature index:  6 \n",
      "\n",
      "Misclassified samples: 253\n",
      "Accuracy: 0.89 for feature index:  7 \n",
      "\n",
      "Misclassified samples: 824\n",
      "Accuracy: 0.63 for feature index:  8 \n",
      "\n",
      "Misclassified samples: 994\n",
      "Accuracy: 0.55 for feature index:  9 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  10 \n",
      "\n",
      "Misclassified samples: 1026\n",
      "Accuracy: 0.54 for feature index:  11 \n",
      "\n",
      "Misclassified samples: 761\n",
      "Accuracy: 0.66 for feature index:  12 \n",
      "\n",
      "Misclassified samples: 330\n",
      "Accuracy: 0.85 for feature index:  13 \n",
      "\n",
      "Misclassified samples: 1025\n",
      "Accuracy: 0.54 for feature index:  14 \n",
      "\n",
      "Misclassified samples: 942\n",
      "Accuracy: 0.57 for feature index:  15 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  16 \n",
      "\n",
      "Misclassified samples: 1176\n",
      "Accuracy: 0.47 for feature index:  17 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  18 \n",
      "\n",
      "Misclassified samples: 941\n",
      "Accuracy: 0.57 for feature index:  19 \n",
      "\n",
      "Misclassified samples: 1268\n",
      "Accuracy: 0.43 for feature index:  20 \n",
      "\n",
      "Misclassified samples: 1220\n",
      "Accuracy: 0.45 for feature index:  21 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  22 \n",
      "\n",
      "Misclassified samples: 969\n",
      "Accuracy: 0.56 for feature index:  23 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  24 \n",
      "\n",
      "Misclassified samples: 682\n",
      "Accuracy: 0.69 for feature index:  25 \n",
      "\n",
      "Misclassified samples: 1090\n",
      "Accuracy: 0.51 for feature index:  26 \n",
      "\n",
      "Misclassified samples: 1353\n",
      "Accuracy: 0.39 for feature index:  27 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  28 \n",
      "\n",
      "Misclassified samples: 1269\n",
      "Accuracy: 0.43 for feature index:  29 \n",
      "\n",
      "Feature Indexes with higher than 60% accuracy are:  [7, 8, 12, 13, 25]\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "high_acc = []\n",
    "\n",
    "for i in range(30):\n",
    "    X = df.iloc[:, [i]].values  #To create weights\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    #Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "    p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "    p.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = p.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    if acc >= 0.60:\n",
    "        high_acc.append(i)\n",
    "    \n",
    "    print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "    print('Accuracy: %.2f' % acc, 'for feature index: ', i, '\\n')\n",
    "    i =+ 1 \n",
    "    \n",
    "print('Feature Indexes with higher than 60% accuracy are: ', high_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this change we have more indexes to evaluate!  So we'll do what we did above again in order to determine if there is a better evaluation that can be done on this data, only now with all the different variations found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 466\n",
      "Accuracy: 0.79 for indexes: 7 & 8\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 8]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 372\n",
      "Accuracy: 0.83 for indexes: 7 & 12\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 12]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 231\n",
      "Accuracy: 0.90 for indexes: 7 & 13\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 13]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 353\n",
      "Accuracy: 0.84 for indexes: 7 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 824\n",
      "Accuracy: 0.63 for indexes: 8 & 12\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [8, 12]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 8 & 12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 391\n",
      "Accuracy: 0.82 for indexes: 8 & 13\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [8, 13]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 8 & 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 682\n",
      "Accuracy: 0.69 for indexes: 8 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [8, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 8 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 776\n",
      "Accuracy: 0.65 for indexes: 12 & 13\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [12, 13]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 12 & 13')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 756\n",
      "Accuracy: 0.66 for indexes: 12 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [12, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 12 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 417\n",
      "Accuracy: 0.81 for indexes: 13 & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [13, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 13 & 25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 315\n",
      "Accuracy: 0.86 for indexes: 7, 8, 12, 13, & 25\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [7, 8, 12, 13, 25]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for feature indexes: 7, 8, 12, 13, & 25')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this evaluation, we can see that using indexes 7 & 13 with 80% training data and 20% testing data, we are able to get to **90% accurate evaluation of the samples being classified properly.**\n",
    "\n",
    "By further analizing the entire set of indexes with both the 70/30 and 80/20 splits, we are able to see the accuracy of using the entire data set.  The **80/20 split results in higher accuracy at 91%**, which is barely higher than using just two indexes, 7  & 13, with the same training / testing rates.  This may indicate that fewer features are necessary to accurately assess Phishing URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 369\n",
      "Accuracy: 0.89 for ALL indexes with 70/30 training/testing split\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for ALL indexes with 70/30 training/testing split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 203\n",
      "Accuracy: 0.91 for ALL indexes with 80/20 training/testing split\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:, 30].values#Indicates which column we want y to focus on\n",
    "# 30 == 31 because the array begins at 0\n",
    "\n",
    "X = df.iloc[:, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#Perceptron function handles the creation of weights.  Never explicitly stated.\n",
    "p = Perceptron(max_iter=40, eta0=0.1, random_state=0)\n",
    "p.fit(X_train, y_train)\n",
    "\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred), 'for ALL indexes with 80/20 training/testing split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
