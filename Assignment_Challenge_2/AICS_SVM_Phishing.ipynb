{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Used to Train and Analyze Phishing Data ##\n",
    "\n",
    "This lab project goes over review of the phishing dataset again, but instead of using Logistic Regression this time we are utilizing SVM. As this follows the steps of our previous SVM review of the spam dataset, the code below should look familiar.\n",
    "\n",
    "# Brief Review #\n",
    "\n",
    "**Hyperplanes** is the seporator between classes as seen in this image:\n",
    "\n",
    "![alt text](http://vbehzadan.com/AISec/SVM1.png)\n",
    "\n",
    "_Space_ in the realm of Data Science is considered a _set_.  They are called _spaces_ because mathmaticians think of data in geometric forms.  Example: The room we are in has three dimensions, this is data in space or in a geometric form.\n",
    "\n",
    "A **prefix margin** is that space between the hyperplane line and the data being seporated.  To optimize the prefix margin, the _goal is to maximize the distance between the points of the classes_ (not distance from hyperplane and data but data and data).  This is using training data and the goal here is to keep the hyperplane generalized enough to avoid over or underfitting.  Wider margin allows for wider variations and thus correspond to fewer classification errors.\n",
    "\n",
    "The nearest training data is known as a **support vector**.  If this is a data point, why is it called a vector?\n",
    "\n",
    "The prefix margin corresponds to the $μ$(mu) symbol in the above equation.  This interacts with the bias in order to create the boundary (margin) of possitive value identification/labeling.  Without the bias term the hyperplane may go through or overlap with data which could otherwise be positively analized as one value or the other (and so on based on number of features being evaluated).\n",
    "\n",
    "Bias ($β$) does not change once training is complete, similar to weights.  In order to update the bias the model will need to be retrained to retain / update accuracy.  Happens frequently in the real world.\n",
    "\n",
    "The trainer / designer does not usually identify $μ$.  The model may be able to identify this itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up python coding environment\n",
    "# Will return later to add plotting features\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = np.genfromtxt(os.path.join('Data','phishing_dataset.csv'), delimiter=',', dtype=np.int32)\n",
    "samples = df[:,:-1]\n",
    "targets = df[:, -1]\n",
    "\n",
    "# Once samples and targets are identified, it's time to train!\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         samples, targets, test_size=0.3, random_state=0)\n",
    "#X = input; y = \n",
    "#hyper parameter -- chosen by ml engineer\n",
    "#typically go with 20/80 or 30/70 split for test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVC defines the weights\n",
    "# Support Vector Config\n",
    "# Kernel indicates what f is in the equation being done to the data to find the hyperplane\n",
    "# C is the regularization parameter\n",
    "# random_state is a pseudo random number gerator used to shuffle data.  VERY IMPORTANT GOING FORWARD\n",
    "#       allows us to reproduce the pseudo random number again thanks to the seed fed to it.\n",
    "#       A seed is an input/element which typically is not known to the user (pseudo random).  Replace 'time' element in most cases.\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified samples: 257\n",
      "Accuracy: 0.92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Misclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "# Accuracy is test time, not training time!\n",
    "# This is doing better than perceptron because: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
