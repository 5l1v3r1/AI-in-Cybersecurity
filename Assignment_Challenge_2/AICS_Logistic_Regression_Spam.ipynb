{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3 Assignment: Logistic Regression for Spam Analysis ##\n",
    "\n",
    "This lab project goes over review of the spam data set again, but instead of using SVM this time we are utilizing Logistic Regression.  As this follows the steps of our previous Logistic Regression review of the Phishing dataset, the code below should look familiar.\n",
    "\n",
    "# Brief Review #\n",
    "\n",
    "Let's quickly review what Logistic Regression is:\n",
    "\n",
    "The linear regression model is characterized by the fact that the data is represented as sums of features, leading to a straight line in the Cartesian plane. In the following image:\n",
    "\n",
    "<div>\n",
    "<img src=\"http://vbehzadan.com/AISec/linreg1.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "- X = the series of $x_{1}, ..., x_{n}$\n",
    "- w = weights\n",
    "- $Î²$ = bias\n",
    "\n",
    "How is this model different from perceptron?\n",
    "- There is no outlined activation function (kernel function) or $f$\n",
    "\n",
    "Optimization objective:\n",
    "\n",
    "The weights determine how important each feature is.  Even in this form of writing out the equation, $w_{1}x_{1}, ..., w_{n}x_{n}$ still are paired together.  This may be reminisent of corrolation.\n",
    "\n",
    "There remains a slight problem with linear regression for classification problems, these equations are for prediction problems.  The reason behind this is that linear regression is mean to minimize forecasting error which causes further classification errors.\n",
    "> Consider this enforced and enhanced overfitting.\n",
    "> Desire is to find a hyperplane very close (minimum prefix margin) to the data seporation.\n",
    "\n",
    "To remediate this problem, estimate the probability of samples for individual classes.  We want to train a model which has **n** input features and **m** outputs.  _This is **not** a n inputs to 1 output problem!_\n",
    "SVM can be used, or multi-layer perceptrons can be used as well to remediate this issue.\n",
    "\n",
    "With multiple outputs, the algorithm is evaluating which has the highest probability among the multiple inputs.  The output with the highest probability will be taken as the main or used output.\n",
    "\n",
    "How do we evaluate the input of a class resulting in an output?  (See below image):\n",
    "<div>\n",
    "<img src=\"http://vbehzadan.com/AISec/logistic1.png\" width=\"700\"/>\n",
    "</div>\n",
    "\n",
    "- P = probability\n",
    "- c = classification\n",
    "- x = input\n",
    "- sigmoid function: $e^{z}/(1 + e^{z})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up coding environment for the notebook\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "df = pd.read_csv(os.path.join('Data','sms_spam_svm.csv'))\n",
    "\n",
    "y = df.iloc[:, 0].values\n",
    "y = np.where(y == 'spam', -1, 1)\n",
    "#Outputs are a scalar (number), so the strings need to be converted into numbers for evaluation.\n",
    "#first number is if true, second number is if false.\n",
    "\n",
    "X = df.iloc[:, [1, 2]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training_samples, testing_samples, training_targets, testing_targets = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "log_classifier = LogisticRegression()\n",
    "log_classifier.fit(training_samples, training_targets)\n",
    "predictions = log_classifier.predict(testing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 84.44444444444444\n"
     ]
    }
   ],
   "source": [
    "accuracy = 100.0 * accuracy_score(testing_targets, predictions)\n",
    "print (\"Logistic Regression accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
